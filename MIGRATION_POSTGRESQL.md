# Migration PostgreSQL - Guide Complet

## ðŸŽ¯ Vue d'ensemble

Cette migration fait passer le systÃ¨me de stockage des monstres d'un systÃ¨me basÃ© sur des fichiers JSON vers une vraie base de donnÃ©es PostgreSQL avec pgAdmin pour la visualisation.

## ðŸ”„ Changements Majeurs

### Architecture de Persistance

**Avant:**
- Stockage des monstres en fichiers JSON dans `app/static/jsons/`
- MÃ©tadonnÃ©es sÃ©parÃ©es dans `app/static/metadata/`
- Dossiers par Ã©tat (generated, approved, transmitted, etc.)
- Pas de transactions, cohÃ©rence difficile Ã  garantir

**AprÃ¨s:**
- Base de donnÃ©es PostgreSQL relationnelle
- Table `monsters` avec donnÃ©es JSON intÃ©grÃ©es
- Table `state_transitions` pour l'historique complet
- Transactions ACID garanties
- RequÃªtes SQL performantes avec index

### Nouveaux Services

#### PostgreSQL
- **Port:** 5432
- **Base de donnÃ©es:** gatcha_db
- **Utilisateur:** gatcha_user
- **Password:** gatcha_password

#### pgAdmin
- **URL:** http://localhost:5050
- **Email:** admin@gatcha.local
- **Password:** admin

## ðŸ“¦ Nouveaux Fichiers

```
app/
  models/
    __init__.py          # Exports des modÃ¨les
    base.py              # Configuration SQLAlchemy
    monster_model.py     # ModÃ¨les Monster et StateTransition
    
scripts/
  migrate_json_to_postgres.py  # Script de migration

.env.example              # Template de configuration
```

## ðŸ”§ Configuration

### 1. Variables d'Environnement

Copier `.env.example` vers `.env` et configurer:

```bash
# PostgreSQL
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_USER=gatcha_user
POSTGRES_PASSWORD=gatcha_password
POSTGRES_DB=gatcha_db
```

### 2. DÃ©pendances Python

Nouvelles dÃ©pendances ajoutÃ©es Ã  `requirements.txt`:
- `sqlalchemy>=2.0.0` - ORM pour PostgreSQL
- `psycopg2-binary>=2.9.0` - Driver PostgreSQL
- `alembic>=1.13.0` - Migrations de schÃ©ma (optionnel)

## ðŸš€ Installation et Migration

### Ã‰tape 1: ArrÃªter l'application existante

```bash
docker-compose down
```

### Ã‰tape 2: Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

### Ã‰tape 3: DÃ©marrer les services avec PostgreSQL

```bash
docker-compose up -d
```

Cela dÃ©marre:
- API (port 8000)
- PostgreSQL (port 5432)
- pgAdmin (port 5050)
- MinIO (ports 9000, 9001)

### Ã‰tape 4: VÃ©rifier que la DB est prÃªte

```bash
docker-compose logs postgres
# Attendre: "database system is ready to accept connections"
```

### Ã‰tape 5: Migrer les donnÃ©es existantes

```bash
# Dry run pour vÃ©rifier
python scripts/migrate_json_to_postgres.py --dry-run

# Migration rÃ©elle
python scripts/migrate_json_to_postgres.py
```

Le script va:
- Lire tous les fichiers metadata JSON
- Trouver les fichiers monster JSON correspondants
- CrÃ©er les entrÃ©es dans PostgreSQL
- Migrer l'historique des transitions

### Ã‰tape 6: VÃ©rifier la migration

AccÃ©der Ã  pgAdmin: http://localhost:5050

1. Se connecter avec `admin@gatcha.local` / `admin`
2. Ajouter un serveur:
   - **Host:** postgres
   - **Port:** 5432
   - **Database:** gatcha_db
   - **Username:** gatcha_user
   - **Password:** gatcha_password
3. Explorer les tables `monsters` et `state_transitions`

## ðŸ“Š SchÃ©ma de Base de DonnÃ©es

### Table: monsters

| Colonne | Type | Description |
|---------|------|-------------|
| id | INTEGER | ClÃ© primaire auto-incrÃ©mentÃ©e |
| monster_id | STRING | UUID unique du monstre |
| filename | STRING | Nom du fichier original |
| state | ENUM | Ã‰tat actuel (GENERATED, APPROVED, etc.) |
| monster_data | JSON | Toutes les donnÃ©es du monstre (nom, stats, skills) |
| created_at | TIMESTAMP | Date de crÃ©ation |
| updated_at | TIMESTAMP | DerniÃ¨re modification |
| generated_by | STRING | Source de gÃ©nÃ©ration (gemini, etc.) |
| generation_prompt | TEXT | Prompt utilisÃ© |
| is_valid | BOOLEAN | Validation rÃ©ussie? |
| validation_errors | JSON | Erreurs de validation |
| reviewed_by | STRING | Nom de l'admin reviewer |
| review_date | TIMESTAMP | Date de review |
| review_notes | TEXT | Notes de review |
| transmitted_at | TIMESTAMP | Date de transmission |
| transmission_attempts | INTEGER | Nombre de tentatives |
| last_transmission_error | TEXT | DerniÃ¨re erreur |
| invocation_api_id | STRING | ID dans l'API d'invocation |
| image_path | STRING | Chemin de l'image |
| metadata_extra | JSON | MÃ©tadonnÃ©es additionnelles |

**Index:**
- `monster_id` (UNIQUE)
- `state`

### Table: state_transitions

| Colonne | Type | Description |
|---------|------|-------------|
| id | INTEGER | ClÃ© primaire |
| monster_db_id | INTEGER | FK vers monsters(id) |
| from_state | ENUM | Ã‰tat de dÃ©part |
| to_state | ENUM | Ã‰tat d'arrivÃ©e |
| timestamp | TIMESTAMP | Date de transition |
| actor | STRING | Acteur (system, admin, user) |
| note | TEXT | Note descriptive |

**Index:**
- `monster_db_id`

## ðŸ” Utilisation de pgAdmin

### Se connecter Ã  la base

1. Ouvrir http://localhost:5050
2. Login: `admin@gatcha.local` / `admin`
3. Ajouter un nouveau serveur (clic droit sur Servers)
4. Onglet General:
   - Name: Gatcha DB
5. Onglet Connection:
   - Host: `postgres`
   - Port: `5432`
   - Database: `gatcha_db`
   - Username: `gatcha_user`
   - Password: `gatcha_password`

### RequÃªtes Utiles

**Compter les monstres par Ã©tat:**
```sql
SELECT state, COUNT(*) as count
FROM monsters
GROUP BY state
ORDER BY count DESC;
```

**Voir l'historique d'un monstre:**
```sql
SELECT m.monster_id, m.monster_data->>'nom' as name,
       st.from_state, st.to_state, st.timestamp, st.actor, st.note
FROM monsters m
JOIN state_transitions st ON m.id = st.monster_db_id
WHERE m.monster_id = 'YOUR_MONSTER_ID'
ORDER BY st.timestamp;
```

**Monstres avec erreurs de validation:**
```sql
SELECT monster_id, filename, monster_data->>'nom' as name,
       validation_errors
FROM monsters
WHERE is_valid = false;
```

**Monstres rÃ©cemment gÃ©nÃ©rÃ©s:**
```sql
SELECT monster_id, monster_data->>'nom' as name,
       monster_data->>'element' as element,
       monster_data->>'rang' as rank,
       state, created_at
FROM monsters
ORDER BY created_at DESC
LIMIT 10;
```

## ðŸ› ï¸ DÃ©veloppement

### AccÃ¨s Direct Ã  la DB

```bash
# Via Docker
docker exec -it gatcha_postgres psql -U gatcha_user -d gatcha_db

# Commandes psql utiles
\dt              # Lister les tables
\d monsters      # DÃ©crire la table monsters
\q               # Quitter
```

### Backup de la Database

```bash
# Exporter
docker exec gatcha_postgres pg_dump -U gatcha_user gatcha_db > backup.sql

# Restaurer
docker exec -i gatcha_postgres psql -U gatcha_user gatcha_db < backup.sql
```

### Reset de la Database

```bash
docker-compose down -v  # Supprime les volumes
docker-compose up -d
python scripts/migrate_json_to_postgres.py
```

## âš ï¸ Points d'Attention

### DonnÃ©es Existantes

- Les fichiers JSON originaux **ne sont pas supprimÃ©s** par la migration
- Ils restent dans `app/static/` comme backup
- AprÃ¨s validation, vous pouvez les archiver

### Performance

- Les requÃªtes SQL sont beaucoup plus rapides que la lecture de fichiers
- Index sur `monster_id` et `state` pour des performances optimales
- Pool de connexions configurÃ© (10 connexions, max 20)

### Transactions

- Toutes les opÃ©rations utilisent des transactions
- En cas d'erreur, rollback automatique
- Plus de problÃ¨mes de cohÃ©rence entre metadata et monster data

## ðŸ”„ Rollback (si nÃ©cessaire)

Si vous devez revenir aux fichiers JSON:

1. Les fichiers originaux sont toujours dans `app/static/`
2. Checkout le commit prÃ©cÃ©dent la migration
3. RedÃ©marrer avec `docker-compose down && docker-compose up`

## ðŸ“š Documentation API

Les endpoints API restent **identiques**, seule la couche de persistance change:

- `GET /api/v1/admin/monsters` - Liste des monstres
- `GET /api/v1/admin/monsters/{id}` - DÃ©tails d'un monstre
- `POST /api/v1/admin/monsters/{id}/review` - Review
- `POST /api/v1/transmission/transmit/{id}` - Transmission

## ðŸŽ‰ Avantages de la Migration

âœ… **Performance:** RequÃªtes SQL beaucoup plus rapides que lecture de fichiers  
âœ… **FiabilitÃ©:** Transactions ACID, pas de corruption de donnÃ©es  
âœ… **RequÃªtes:** SQL puissant pour analytics et recherches complexes  
âœ… **ScalabilitÃ©:** PostgreSQL peut gÃ©rer des millions de monstres  
âœ… **Visualisation:** pgAdmin pour explorer et analyser les donnÃ©es  
âœ… **Backup:** Outils professionnels de backup PostgreSQL  
âœ… **Historique:** Tracking complet avec state_transitions  

## ðŸ› Troubleshooting

### ProblÃ¨me: "Connection refused" Ã  PostgreSQL

```bash
# VÃ©rifier que PostgreSQL dÃ©marre bien
docker-compose logs postgres

# Attendre le healthcheck
docker-compose ps
```

### ProblÃ¨me: Migration Ã©choue

```bash
# VÃ©rifier les logs
python scripts/migrate_json_to_postgres.py 2>&1 | tee migration.log

# VÃ©rifier la structure
docker exec -it gatcha_postgres psql -U gatcha_user -d gatcha_db -c "\dt"
```

### ProblÃ¨me: pgAdmin ne se connecte pas

- Utiliser `postgres` comme hostname (pas `localhost`)
- VÃ©rifier que les services sont sur le mÃªme rÃ©seau Docker

## ðŸ“ž Support

Pour toute question sur la migration, consultez:
- Logs: `docker-compose logs`
- Database: pgAdmin http://localhost:5050
- API Docs: http://localhost:8000/docs
